using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Drawing;
using System.Drawing.Drawing2D;
using System.Drawing.Imaging;
using System.IO;
using System.Linq;
using CTSegmenter;
using Microsoft.ML.OnnxRuntime;
using Microsoft.ML.OnnxRuntime.Tensors;

/// <summary>
/// A unified CTMemorySegmenter that supports both older 9/10-argument constructors
/// and the new 2-argument constructor for SAM 2.1 (encoder + decoder).
/// Also includes optional debugging logic to investigate black-mask issues.
/// </summary>
public class CTMemorySegmenter : IDisposable
{
    // ------------------------------------------------------------------------
    // Fields from older code
    // ------------------------------------------------------------------------
    private string _imageEncoderPath;
    private string _promptEncoderPath;  // older SAM only
    private string _maskDecoderPath;
    private string _memoryEncoderPath;  // older SAM only
    private string _memoryAttentionPath;// older SAM only
    private string _mlpPath;            // older SAM only
    private int _imageInputSize;
    private bool _canUseTextPrompts;
    private bool _enableMlp;
    private bool _useCpuExecutionProvider;

    // The ONNX runtime sessions
    private InferenceSession _encoderSession;
    private InferenceSession _decoderSession;

    // Option flags
    public bool StorePreviousEmbeddings { get; set; } = true;   // older code references
    public bool UseSelectiveHoleFilling { get; set; } = false;  // older code references

    /// <summary>
    /// Mask binarization threshold in [0..1]. Default 0.5 => logit=0 => foreground.
    /// </summary>
    public float MaskBinarizationThreshold { get; set; } = 0.0f;

    /// <summary>
    /// When true, we add debug logs, min/max stats, optionally save mask images, etc.
    /// </summary>
    public bool DebugEnabled { get; set; } = true;

    /// <summary>
    /// If DebugEnabled is true, and this is also true, we save debug images to DebugOutputPath.
    /// </summary>
    public bool SaveDebugImages { get; set; } = true;

    /// <summary>
    /// Directory where we save debug images if SaveDebugImages is true.
    /// Defaults to Application.StartupPath + "/DebugMasks"
    /// </summary>
    public string DebugOutputPath { get; set; } = ".\\DebugInfos";

    private static void Log(string msg) => Logger.Log(msg);

    // ------------------------------------------------------------------------
    // Constructors
    // ------------------------------------------------------------------------

    /// <summary>
    /// Minimal new constructor for SAM 2.1 usage: just pass encoder+decoder ONNX paths.
    /// </summary>
    public CTMemorySegmenter(string encoderOnnxPath, string decoderOnnxPath)
    {
        _imageEncoderPath = encoderOnnxPath;
        _maskDecoderPath = decoderOnnxPath;

        var options = new SessionOptions();
        options.AppendExecutionProvider_CPU();  // or GPU if desired
        _encoderSession = new InferenceSession(_imageEncoderPath, options);
        _decoderSession = new InferenceSession(_maskDecoderPath, options);

        // Default input size 1024 for SAM 2.1
        _imageInputSize = 1024;

        Log("[CTMemorySegmenter] Created with 2-arg constructor (SAM 2.1).");
    }

    /// <summary>
    /// Old 9-argument constructor signature, chaining to the 10-argument version with CPU=true.
    /// </summary>
    public CTMemorySegmenter(
        string imageEncoderPath,
        string promptEncoderPath,
        string maskDecoderPath,
        string memoryEncoderPath,
        string memoryAttentionPath,
        string mlpPath,
        int imageInputSize,
        bool canUseTextPrompts,
        bool enableMlp)
        : this(imageEncoderPath, promptEncoderPath, maskDecoderPath, memoryEncoderPath,
               memoryAttentionPath, mlpPath, imageInputSize, canUseTextPrompts, enableMlp, true)
    {
        // no body needed
    }

    /// <summary>
    /// Old 10-argument constructor: originally for older SAM. We'll adapt it to also handle SAM 2.1 if so desired.
    /// </summary>
    public CTMemorySegmenter(
    string imageEncoderPath,
    string promptEncoderPath,
    string maskDecoderPath,
    string memoryEncoderPath,
    string memoryAttentionPath,
    string mlpPath,
    int imageInputSize,
    bool canUseTextPrompts,
    bool enableMlp,
    bool useCpuExecutionProvider)
    {
        // Store primary paths
        _imageEncoderPath = imageEncoderPath;
        _maskDecoderPath = maskDecoderPath;
        _imageInputSize = imageInputSize;
        _useCpuExecutionProvider = useCpuExecutionProvider;
        // Log and ignore legacy model paths (not used in SAM 2.1)
        if (!string.IsNullOrEmpty(promptEncoderPath) || !string.IsNullOrEmpty(memoryEncoderPath))
            Log("[CTMemorySegmenter] Legacy SAM model support is removed. Ignoring prompt/memory encoder paths.");

        // Initialize ONNX runtime sessions for encoder and decoder only
        var options = new SessionOptions();
        if (!_useCpuExecutionProvider)
        {
            try { options.AppendExecutionProvider_CUDA(); }
            catch { options = new SessionOptions(); options.AppendExecutionProvider_CPU(); }
        }
        else
        {
            options.AppendExecutionProvider_CPU();
        }
        if (File.Exists(_imageEncoderPath) && File.Exists(_maskDecoderPath))
        {
            _encoderSession = new InferenceSession(_imageEncoderPath, options);
            _decoderSession = new InferenceSession(_maskDecoderPath, options);
            Log("[CTMemorySegmenter] Initialized SAM2.1 encoder/decoder sessions.");
        }
        else
        {
            Log("[CTMemorySegmenter] Model files not found – encoder/decoder not loaded.");
        }
    }

    // ------------------------------------------------------------------------
    // Dispose
    // ------------------------------------------------------------------------
    public void Dispose()
    {
        _encoderSession?.Dispose();
        _decoderSession?.Dispose();
    }

    // ------------------------------------------------------------------------
    // XY methods
    // ------------------------------------------------------------------------
    /// <summary>
    /// Process a single XY slice (returns the single best mask as Bitmap).
    /// Overload also returns a bool[,] array of mask bits.
    /// </summary>
    public Bitmap ProcessXYSlice(
        int sliceIndex,
        Bitmap baseXY,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName,
        out bool[,] maskBits)
    {
        maskBits = null;
        if (_encoderSession == null || _decoderSession == null)
        {
            Log("[ProcessXYSlice] No loaded sessions. Returning null.");
            return null;
        }
        if (baseXY == null || slicePoints == null || slicePoints.Count == 0)
        {
            Log("[ProcessXYSlice] Invalid input data. Returning null.");
            return null;
        }
        Log($"[ProcessXYSlice] Segmenting '{targetMaterialName}' in XY slice Z={sliceIndex}.");

        // 1) Convert baseXY to float tensor of shape (1,3,1024,1024)
        float[] imageTensor = BitmapToFloatTensor(baseXY, _imageInputSize, _imageInputSize);
        var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });

        // 2) Run encoder => image_embed, high_res_feats_0, high_res_feats_1
        Tensor<float> imageEmbeddings, highRes0, highRes1;
        using (var encOut = _encoderSession.Run(new[] {
            NamedOnnxValue.CreateFromTensor("image", imageInput)
        }))
        {
            imageEmbeddings = GetFirstTensorOrNull<float>(encOut, "image_embed");
            highRes0 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
            highRes1 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
        }
        if (imageEmbeddings == null || highRes0 == null || highRes1 == null)
        {
            Log("[ProcessXYSlice] Encoder output was missing. Returning null.");
            return null;
        }

        // 3) Build prompt: points for this material => label=1, all other => label=0
        int origW = baseXY.Width;
        int origH = baseXY.Height;
        var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

        // 4) Setup decoder inputs
        var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });
        int batchSize = coordTensor.Dimensions[0]; // typically 1
        var maskInputTensor = new DenseTensor<float>(new float[batchSize * 1 * 256 * 256], new[] { batchSize, 1, 256, 256 });
        var hasMaskInputTensor = new DenseTensor<float>(new float[batchSize], new[] { batchSize });

        // 5) Run decoder => output masks + IoU
        Tensor<float> masksTensor, iouTensor;
        using (var decOut = _decoderSession.Run(new List<NamedOnnxValue> {
            NamedOnnxValue.CreateFromTensor("image_embed",      imageEmbeddings),
            NamedOnnxValue.CreateFromTensor("high_res_feats_0", highRes0),
            NamedOnnxValue.CreateFromTensor("high_res_feats_1", highRes1),
            NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
            NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
            NamedOnnxValue.CreateFromTensor("mask_input",       maskInputTensor),
            NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskInputTensor),
            NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
        }))
        {
            masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");   // shape [1,3,256,256]
            iouTensor = GetFirstTensorOrNull<float>(decOut, "iou_predictions"); // shape [1,3]
        }

        if (masksTensor == null || iouTensor == null)
        {
            Log("[ProcessXYSlice] Decoder output is missing or invalid. Returning null.");
            return null;
        }

        int outC = masksTensor.Dimensions[1]; // typically 3
        if (outC == 0)
        {
            Log("[ProcessXYSlice] Decoder returned 0 channels. Returning null.");
            return null;
        }

        // If debugging, dump stats for each channel
        if (DebugEnabled)
        {
            Log($"[ProcessXYSlice] iouTensor => shape=[1, {outC}]");
            for (int c = 0; c < outC; c++)
            {
                float iouVal = iouTensor[0, c];
                Log($"   Channel {c}: IoU={iouVal:F4}");
            }
            // Dump stats for the raw logits
            DumpTensorStats(masksTensor, "XY_single", sliceIndex);
        }

        // Pick best IoU
        float bestIoU = float.MinValue;
        int bestIndex = 0;
        for (int c = 0; c < outC; c++)
        {
            float iou = iouTensor[0, c];
            if (iou > bestIoU)
            {
                bestIoU = iou;
                bestIndex = c;
            }
        }
        Log($"[ProcessXYSlice] Best channel={bestIndex}, IoU={bestIoU:0.000}");

        // Convert that channel’s logits => binarized mask
        int maskH = masksTensor.Dimensions[2]; // 256
        int maskW = masksTensor.Dimensions[3]; // 256
        var finalMask = BuildMaskFromDecoder(masksTensor, bestIndex, maskW, maskH, origW, origH, out maskBits, sliceIndex, "XY_single");

        return finalMask;
    }

    public Bitmap ProcessXYSlice(
        int sliceIndex,
        Bitmap baseXY,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName)
    {
        bool[,] ignore;
        return ProcessXYSlice(sliceIndex, baseXY, slicePoints, targetMaterialName, out ignore);
    }

    // ------------------------------------------------------------------------
    // XZ methods
    // ------------------------------------------------------------------------
    public Bitmap ProcessXZSlice(
        int fixedY,
        Bitmap baseXZ,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName,
        out bool[,] maskBits)
    {
        maskBits = null;
        if (_encoderSession == null || _decoderSession == null)
        {
            Log("[ProcessXZSlice] No loaded sessions. Returning null.");
            return null;
        }
        if (baseXZ == null || slicePoints == null || slicePoints.Count == 0)
        {
            Log("[ProcessXZSlice] Invalid input data. Returning null.");
            return null;
        }
        Log($"[ProcessXZSlice] Segmenting '{targetMaterialName}' in XZ slice Y={fixedY}.");

        float[] imageTensor = BitmapToFloatTensor(baseXZ, _imageInputSize, _imageInputSize);
        var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });

        Tensor<float> imageEmbeddings, highRes0, highRes1;
        using (var encOut = _encoderSession.Run(new[] {
            NamedOnnxValue.CreateFromTensor("image", imageInput)
        }))
        {
            imageEmbeddings = GetFirstTensorOrNull<float>(encOut, "image_embed");
            highRes0 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
            highRes1 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
        }
        if (imageEmbeddings == null || highRes0 == null || highRes1 == null)
        {
            Log("[ProcessXZSlice] Encoder outputs missing. Returning null.");
            return null;
        }

        int origW = baseXZ.Width;
        int origH = baseXZ.Height;
        var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

        var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });
        int batchSize = coordTensor.Dimensions[0];
        var maskInputTensor = new DenseTensor<float>(new float[batchSize * 1 * 256 * 256], new[] { batchSize, 1, 256, 256 });
        var hasMaskInputTensor = new DenseTensor<float>(new float[batchSize], new[] { batchSize });

        Tensor<float> masksTensor, iouTensor;
        using (var decOut = _decoderSession.Run(new List<NamedOnnxValue> {
            NamedOnnxValue.CreateFromTensor("image_embed",      imageEmbeddings),
            NamedOnnxValue.CreateFromTensor("high_res_feats_0", highRes0),
            NamedOnnxValue.CreateFromTensor("high_res_feats_1", highRes1),
            NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
            NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
            NamedOnnxValue.CreateFromTensor("mask_input",       maskInputTensor),
            NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskInputTensor),
            NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
        }))
        {
            masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");
            iouTensor = GetFirstTensorOrNull<float>(decOut, "iou_predictions");
        }
        if (masksTensor == null || iouTensor == null) return null;

        int outC = masksTensor.Dimensions[1];
        if (DebugEnabled)
        {
            for (int c = 0; c < outC; c++)
            {
                float iouVal = iouTensor[0, c];
                Log($"[ProcessXZSlice] Channel {c}, IoU={iouVal:F3}");
            }
            DumpTensorStats(masksTensor, "XZ_single", fixedY);
        }

        float bestIoU = float.MinValue;
        int bestIndex = 0;
        for (int c = 0; c < outC; c++)
        {
            float iou = iouTensor[0, c];
            if (iou > bestIoU)
            {
                bestIoU = iou;
                bestIndex = c;
            }
        }
        Log($"[ProcessXZSlice] bestIndex={bestIndex}, IoU={bestIoU:F3}");

        int maskH = masksTensor.Dimensions[2];
        int maskW = masksTensor.Dimensions[3];
        var finalMask = BuildMaskFromDecoder(masksTensor, bestIndex, maskW, maskH, origW, origH,
                                             out maskBits, fixedY, "XZ_single");

        return finalMask;
    }

    public Bitmap ProcessXZSlice(
        int fixedY,
        Bitmap baseXZ,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName)
    {
        bool[,] dummy;
        return ProcessXZSlice(fixedY, baseXZ, slicePoints, targetMaterialName, out dummy);
    }

    // ------------------------------------------------------------------------
    // YZ methods
    // ------------------------------------------------------------------------
    public Bitmap ProcessYZSlice(
        int fixedX,
        Bitmap baseYZ,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName,
        out bool[,] maskBits)
    {
        maskBits = null;
        if (_encoderSession == null || _decoderSession == null)
        {
            Log("[ProcessYZSlice] No loaded sessions. Returning null.");
            return null;
        }
        if (baseYZ == null || slicePoints == null || slicePoints.Count == 0)
        {
            Log("[ProcessYZSlice] Invalid input data. Returning null.");
            return null;
        }
        Log($"[ProcessYZSlice] Segmenting '{targetMaterialName}' in YZ slice X={fixedX}.");

        float[] imageTensor = BitmapToFloatTensor(baseYZ, _imageInputSize, _imageInputSize);
        var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });

        Tensor<float> imageEmbeddings, highRes0, highRes1;
        using (var encOut = _encoderSession.Run(new[] {
            NamedOnnxValue.CreateFromTensor("image", imageInput)
        }))
        {
            imageEmbeddings = GetFirstTensorOrNull<float>(encOut, "image_embed");
            highRes0 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
            highRes1 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
        }
        if (imageEmbeddings == null || highRes0 == null || highRes1 == null) return null;

        int origW = baseYZ.Width;
        int origH = baseYZ.Height;
        var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

        var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });
        int batchSize = coordTensor.Dimensions[0];
        var maskInputTensor = new DenseTensor<float>(new float[batchSize * 1 * 256 * 256], new[] { batchSize, 1, 256, 256 });
        var hasMaskInputTensor = new DenseTensor<float>(new float[batchSize], new[] { batchSize });

        Tensor<float> masksTensor, iouTensor;
        using (var decOut = _decoderSession.Run(new List<NamedOnnxValue> {
            NamedOnnxValue.CreateFromTensor("image_embed",      imageEmbeddings),
            NamedOnnxValue.CreateFromTensor("high_res_feats_0", highRes0),
            NamedOnnxValue.CreateFromTensor("high_res_feats_1", highRes1),
            NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
            NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
            NamedOnnxValue.CreateFromTensor("mask_input",       maskInputTensor),
            NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskInputTensor),
            NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
        }))
        {
            masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");
            iouTensor = GetFirstTensorOrNull<float>(decOut, "iou_predictions");
        }
        if (masksTensor == null || iouTensor == null) return null;

        int outC = masksTensor.Dimensions[1];
        if (DebugEnabled)
        {
            for (int c = 0; c < outC; c++)
            {
                float iouVal = iouTensor[0, c];
                Log($"[ProcessYZSlice] Channel {c}, IoU={iouVal:F3}");
            }
            DumpTensorStats(masksTensor, "YZ_single", fixedX);
        }

        float bestIoU = float.MinValue;
        int bestIndex = 0;
        for (int c = 0; c < outC; c++)
        {
            float iou = iouTensor[0, c];
            if (iou > bestIoU)
            {
                bestIoU = iou;
                bestIndex = c;
            }
        }

        int maskH = masksTensor.Dimensions[2];
        int maskW = masksTensor.Dimensions[3];
        var finalMask = BuildMaskFromDecoder(masksTensor, bestIndex, maskW, maskH, origW, origH,
                                             out maskBits, fixedX, "YZ_single");
        return finalMask;
    }

    public Bitmap ProcessYZSlice(
        int fixedX,
        Bitmap baseYZ,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName)
    {
        bool[,] ignore;
        return ProcessYZSlice(fixedX, baseYZ, slicePoints, targetMaterialName, out ignore);
    }

    // ------------------------------------------------------------------------
    // "GetAllMasks" multi-candidate versions
    // ------------------------------------------------------------------------
    /// <summary>
    /// Multi-mask version for XY. Returns all candidate masks as a List, sorted by IoU descending.
    /// </summary>
    public List<Bitmap> ProcessXYSlice_GetAllMasks(
     int sliceIndex,
     Bitmap baseXY,
     List<AnnotationPoint> slicePoints,
     string targetMaterialName)
    {
        var results = new List<Bitmap>();

        // Input validation
        if (_encoderSession == null || _decoderSession == null)
        {
            Log("[ProcessXYSlice_GetAllMasks] Sessions not initialized");
            return results;
        }

        if (baseXY == null || slicePoints == null || slicePoints.Count == 0)
        {
            Log("[ProcessXYSlice_GetAllMasks] Invalid inputs");
            return results;
        }

        // 1. Convert the image to a tensor
        float[] imageTensor = BitmapToFloatTensor(baseXY, _imageInputSize, _imageInputSize);
        var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });

        // 2. Run the encoder
        Tensor<float> imageEmbeddings, highRes0, highRes1;
        using (var encOut = _encoderSession.Run(new[] { NamedOnnxValue.CreateFromTensor("image", imageInput) }))
        {
            imageEmbeddings = GetFirstTensorOrNull<float>(encOut, "image_embed");
            highRes0 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
            highRes1 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
        }

        // 3. Validate encoder outputs
        if (imageEmbeddings == null || highRes0 == null || highRes1 == null)
        {
            Log("[ProcessXYSlice_GetAllMasks] Encoder outputs are null");
            return results;
        }

        // 4. Build prompt tensors
        int origW = baseXY.Width;
        int origH = baseXY.Height;
        int maskH;
        int maskW;
        var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

        // 5. Prepare decoder inputs
        var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });
        int batchSize = coordTensor.Dimensions[0];
        var maskInputTensor = new DenseTensor<float>(new float[batchSize * 1 * 256 * 256], new[] { batchSize, 1, 256, 256 });
        var hasMaskInputTensor = new DenseTensor<float>(new float[batchSize], new[] { batchSize });

        // 6. Run the decoder
        Tensor<float> masksTensor, iouTensor;
        using (var decOut = _decoderSession.Run(new List<NamedOnnxValue> {
        NamedOnnxValue.CreateFromTensor("image_embed",      imageEmbeddings),
        NamedOnnxValue.CreateFromTensor("high_res_feats_0", highRes0),
        NamedOnnxValue.CreateFromTensor("high_res_feats_1", highRes1),
        NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
        NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
        NamedOnnxValue.CreateFromTensor("mask_input",       maskInputTensor),
        NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskInputTensor),
        NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
    }))
        {
            masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");
            iouTensor = GetFirstTensorOrNull<float>(decOut, "iou_predictions");
        }

        // 7. Validate decoder outputs
        if (masksTensor == null || iouTensor == null)
        {
            Log("[ProcessXYSlice_GetAllMasks] Decoder outputs are null");
            return results;
        }

        // 8. Get mask dimensions
        int outC = masksTensor.Dimensions[1];
        if (outC == 0)
        {
            Log("[ProcessXYSlice_GetAllMasks] No mask channels found in output tensor");
            return results;
        }

        // 9. Log tensor dimensions and IoU values
        string maskDimStr = $"{masksTensor.Dimensions[0]},{masksTensor.Dimensions[1]},{masksTensor.Dimensions[2]},{masksTensor.Dimensions[3]}";
        string iouDimStr = $"{iouTensor.Dimensions[0]},{iouTensor.Dimensions[1]}";
        Log($"[ProcessXYSlice_GetAllMasks] masks tensor shape: [{maskDimStr}]");
        Log($"[ProcessXYSlice_GetAllMasks] iou tensor shape: [{iouDimStr}]");

        Log($"[ProcessXYSlice_GetAllMasks] Got {outC} mask candidates (channels). IoUs:");
        for (int chan = 0; chan < outC; chan++)
        {
            float iouValue = chan < iouTensor.Dimensions[1] ? iouTensor[0, chan] : 0.0f;
            Log($"  - Mask {chan}: IoU={iouValue:F4}");

            // Analyze mask content
            float minLogit = float.MaxValue;
            float maxLogit = float.MinValue;
            maskH = masksTensor.Dimensions[2];
            maskW = masksTensor.Dimensions[3];

            for (int y = 0; y < maskH; y++)
            {
                for (int x = 0; x < maskW; x++)
                {
                    float val = masksTensor[0, chan, y, x];
                    minLogit = Math.Min(minLogit, val);
                    maxLogit = Math.Max(maxLogit, val);
                }
            }

            Log($"  - Mask {chan} logit range: min={minLogit:F3}, max={maxLogit:F3}");
        }

        // 10. Sort mask channels by IoU descending
        var sortedIndices = new List<(float iou, int idx)>();
        for (int chan = 0; chan < outC; chan++)
        {
            // Always include all channels even if IoU is zero
            sortedIndices.Add((iouTensor[0, chan], chan));
        }
        sortedIndices.Sort((a, b) => b.iou.CompareTo(a.iou));

        // 11. Convert each mask logits channel to a Bitmap
        maskH = masksTensor.Dimensions[2];
        maskW = masksTensor.Dimensions[3];
        foreach (var pair in sortedIndices)
        {
            int channelIndex = pair.idx;
            bool[,] dummy;
            try
            {
                Bitmap candidateMask = BuildMaskFromDecoder(
                    masksTensor,
                    channelIndex,
                    maskW,
                    maskH,
                    origW,
                    origH,
                    out dummy,
                    sliceIndex,
                    debugTag: $"XY_multi_c{channelIndex}"
                );
                results.Add(candidateMask);
            }
            catch (Exception ex)
            {
                Log($"[ProcessXYSlice_GetAllMasks] Error building mask for channel {channelIndex}: {ex.Message}");
            }
        }

        return results;
    }


    /// <summary>
    /// Multi-mask version for XZ. Returns all candidate masks as a List, sorted by IoU descending.
    /// </summary>
    public List<Bitmap> ProcessXZSlice_GetAllMasks(
    int fixedY,
    Bitmap baseXZ,
    List<AnnotationPoint> slicePoints,
    string targetMaterialName)
{
    var results = new List<Bitmap>();
    if (_encoderSession == null || _decoderSession == null) 
        return results;
    if (baseXZ == null || slicePoints == null || slicePoints.Count == 0) 
        return results;

    // 1) Encode the XZ slice -> image_embed, high_res_feats
    float[] imageTensor = BitmapToFloatTensor(baseXZ, _imageInputSize, _imageInputSize);
    var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });
    Tensor<float> imageEmbeddings, highRes0, highRes1;
    using (var encOut = _encoderSession.Run(new[] { NamedOnnxValue.CreateFromTensor("image", imageInput) }))
    {
        imageEmbeddings = GetFirstTensorOrNull<float>(encOut, "image_embed");
        highRes0        = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
        highRes1        = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
    }
    if (imageEmbeddings == null || highRes0 == null || highRes1 == null)
        return results;

    // 2) Build prompt
    int origW = baseXZ.Width;
    int origH = baseXZ.Height;
    var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

    // 3) Prepare mask_input
    int batchSize = coordTensor.Dimensions[0];
    var maskInputTensor = new DenseTensor<float>(new float[batchSize * 1 * 256 * 256], new[] { batchSize, 1, 256, 256 });
    var hasMaskInputTensor = new DenseTensor<float>(new float[batchSize], new[] { batchSize });
    var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });

    // 4) Decoder => output all mask channels + IoU
    Tensor<float> masksTensor, iouTensor;
    using (var decOut = _decoderSession.Run(new List<NamedOnnxValue> {
        NamedOnnxValue.CreateFromTensor("image_embed",      imageEmbeddings),
        NamedOnnxValue.CreateFromTensor("high_res_feats_0", highRes0),
        NamedOnnxValue.CreateFromTensor("high_res_feats_1", highRes1),
        NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
        NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
        NamedOnnxValue.CreateFromTensor("mask_input",       maskInputTensor),
        NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskInputTensor),
        NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
    }))
    {
        masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");          // shape [1,3,256,256]
        iouTensor   = GetFirstTensorOrNull<float>(decOut, "iou_predictions"); // shape [1,3]
    }
    if (masksTensor == null || iouTensor == null)
        return results;

    int outC = masksTensor.Dimensions[1];
    if (outC == 0) 
        return results;

    // 5) Sort channels by IoU descending
    var iouList = new List<(float iou, int c)>();
    for (int c = 0; c < outC; c++)
        iouList.Add((iouTensor[0,c], c));
    iouList.Sort((a,b) => b.iou.CompareTo(a.iou));

    // 6) Convert each channel’s logits to a Bitmap, in IoU desc order
    int maskH = masksTensor.Dimensions[2];
    int maskW = masksTensor.Dimensions[3];
    foreach (var entry in iouList)
    {
        bool[,] dummy;
        Bitmap candidate = BuildMaskFromDecoder(
            masksTensor,
            entry.c,
            maskW,
            maskH,
            origW,
            origH,
            out dummy
        );
        results.Add(candidate);
    }

    return results;
}

/// <summary>
/// Multi-mask version for YZ. Returns all candidate masks as a List, sorted by IoU descending.
/// </summary>
public List<Bitmap> ProcessYZSlice_GetAllMasks(
    int fixedX,
    Bitmap baseYZ,
    List<AnnotationPoint> slicePoints,
    string targetMaterialName)
{
    var results = new List<Bitmap>();
    if (_encoderSession == null || _decoderSession == null) 
        return results;
    if (baseYZ == null || slicePoints == null || slicePoints.Count == 0) 
        return results;

    // 1) Encode the YZ slice
    float[] imageTensor = BitmapToFloatTensor(baseYZ, _imageInputSize, _imageInputSize);
    var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });
    Tensor<float> imageEmbeddings, highRes0, highRes1;
    using (var encOut = _encoderSession.Run(new[] { NamedOnnxValue.CreateFromTensor("image", imageInput) }))
    {
        imageEmbeddings = GetFirstTensorOrNull<float>(encOut, "image_embed");
        highRes0        = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
        highRes1        = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
    }
    if (imageEmbeddings == null || highRes0 == null || highRes1 == null)
        return results;

    // 2) Prompt
    int origW = baseYZ.Width;
    int origH = baseYZ.Height;
    var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

    // 3) Mask input
    int batchSize = coordTensor.Dimensions[0];
    var maskInputTensor = new DenseTensor<float>(new float[batchSize * 1 * 256 * 256], new[] { batchSize, 1, 256, 256 });
    var hasMaskInputTensor = new DenseTensor<float>(new float[batchSize], new[] { batchSize });
    var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });

    // 4) Decode => all mask channels
    Tensor<float> masksTensor, iouTensor;
    using (var decOut = _decoderSession.Run(new List<NamedOnnxValue> {
        NamedOnnxValue.CreateFromTensor("image_embed",      imageEmbeddings),
        NamedOnnxValue.CreateFromTensor("high_res_feats_0", highRes0),
        NamedOnnxValue.CreateFromTensor("high_res_feats_1", highRes1),
        NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
        NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
        NamedOnnxValue.CreateFromTensor("mask_input",       maskInputTensor),
        NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskInputTensor),
        NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
    }))
    {
        masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");          // shape [1,3,256,256]
        iouTensor   = GetFirstTensorOrNull<float>(decOut, "iou_predictions"); // shape [1,3]
    }
    if (masksTensor == null || iouTensor == null)
        return results;

    int outC = masksTensor.Dimensions[1];
    if (outC == 0) 
        return results;

    // 5) Sort channels by IoU
    var iouList = new List<(float iou,int c)>();
    for (int c = 0; c < outC; c++)
        iouList.Add((iouTensor[0,c], c));
    iouList.Sort((a,b) => b.iou.CompareTo(a.iou));

    int maskH = masksTensor.Dimensions[2];
    int maskW = masksTensor.Dimensions[3];
    // 6) Convert each channel
    foreach (var entry in iouList)
    {
        bool[,] dummy;
        Bitmap candidate = BuildMaskFromDecoder(
            masksTensor,
            entry.c,
            maskW,
            maskH,
            origW,
            origH,
            out dummy
        );
        results.Add(candidate);
    }

    return results;
}


    // ------------------------------------------------------------------------
    // Private helper: Build prompt from points => label=1 if matches targetMaterial, else 0
    // ------------------------------------------------------------------------
    private (DenseTensor<float>, DenseTensor<float>) BuildSinglePromptTensors(
    List<AnnotationPoint> prompts, int origW, int origH, string targetMaterialName)
    {
        // Compute normalized scale factors (to 0..1 range)
        float xDenom = Math.Max(1, origW - 1);
        float yDenom = Math.Max(1, origH - 1);
        var coordsList = new List<float>();
        var labelsList = new List<float>();

        Log($"[BuildSinglePromptTensors] Building prompts for '{targetMaterialName}' with {prompts.Count} points");

        foreach (var p in prompts)
        {
            // Clamp point within image bounds
            float cx = Math.Max(0, Math.Min(p.X, origW - 1));
            float cy = Math.Max(0, Math.Min(p.Y, origH - 1));

            // Normalize coordinates to [0,1] range
            float normX = cx / xDenom;
            float normY = cy / yDenom;

            // FIXED ORDER: X first, then Y (SAM 2.1 expects this order)
            coordsList.Add(normX); // Add X first
            coordsList.Add(normY); // Then Y

            // Label: 1 for target material (foreground prompt), 0 for others (negative prompt)
            bool isFg = p.Label.Equals(targetMaterialName, StringComparison.OrdinalIgnoreCase);
            labelsList.Add(isFg ? 1f : 0f);

            Log($"Point at ({cx},{cy}) normalized to ({normX:F3},{normY:F3}), isForeground={isFg}");
        }

        // If no points, add a dummy point with label -1 (not a point)
        if (coordsList.Count == 0)
        {
            coordsList.Add(0f); coordsList.Add(0f);
            labelsList.Add(-1f);
        }

        // Create tensors of shape [1, numPoints, 2] and [1, numPoints]
        int numPoints = labelsList.Count;
        var coordTensor = new DenseTensor<float>(coordsList.ToArray(), new[] { 1, numPoints, 2 });
        var labelTensor = new DenseTensor<float>(labelsList.ToArray(), new[] { 1, numPoints });

        return (coordTensor, labelTensor);
    }



    // ------------------------------------------------------------------------
    // Private helper: Convert raw logits => binarized mask => upscaled to original size
    // ------------------------------------------------------------------------
    private Bitmap BuildMaskFromDecoder(
    Tensor<float> masksTensor,
    int maskIndex,
    int maskW,
    int maskH,
    int outW,
    int outH,
    out bool[,] maskBits,
    int sliceIndex,
    string debugTag)
    {
        float threshold = MaskBinarizationThreshold;
        maskBits = new bool[maskH, maskW];

        // Log tensor dimensions for debugging
        string dimStr = $"{masksTensor.Dimensions[0]},{masksTensor.Dimensions[1]},{masksTensor.Dimensions[2]},{masksTensor.Dimensions[3]}";
        Log($"[BuildMaskFromDecoder] masksTensor dimensions: [{dimStr}]");

        // Check if maskIndex is valid for this tensor
        if (maskIndex >= masksTensor.Dimensions[1])
        {
            Log($"[BuildMaskFromDecoder] ERROR: maskIndex {maskIndex} out of bounds (max is {masksTensor.Dimensions[1] - 1})");
            // Return an empty black mask as fallback
            Bitmap emptyMask = new Bitmap(outW, outH);
            using (Graphics g = Graphics.FromImage(emptyMask))
            {
                g.Clear(Color.Black);
            }
            return emptyMask;
        }

        // Debug output
        if (DebugEnabled && SaveDebugImages)
        {
            SaveMaskChannelAsImage(masksTensor, maskIndex, sliceIndex, debugTag, rawLogits: true);
        }

        try
        {
            // Build a 256x256 raw mask
            Bitmap rawMask = new Bitmap(maskW, maskH, PixelFormat.Format24bppRgb);

            // Track min/max logit values to see if mask contains usable data
            float minLogit = float.MaxValue;
            float maxLogit = float.MinValue;

            for (int yy = 0; yy < maskH; yy++)
            {
                for (int xx = 0; xx < maskW; xx++)
                {
                    float logit = masksTensor[0, maskIndex, yy, xx];
                    minLogit = Math.Min(minLogit, logit);
                    maxLogit = Math.Max(maxLogit, logit);

                    float prob = 1f / (1f + (float)Math.Exp(-logit)); // sigmoid
                    bool isFg = (prob >= threshold);

                    if (isFg)
                    {
                        rawMask.SetPixel(xx, yy, Color.White);
                        maskBits[yy, xx] = true;
                    }
                    else
                    {
                        rawMask.SetPixel(xx, yy, Color.Black);
                        maskBits[yy, xx] = false;
                    }
                }
            }

            Log($"[BuildMaskFromDecoder] Mask logit range: min={minLogit:F3}, max={maxLogit:F3}");

            // Upscale to output dimensions
            Bitmap finalMask = new Bitmap(outW, outH, PixelFormat.Format24bppRgb);
            using (Graphics g = Graphics.FromImage(finalMask))
            {
                g.InterpolationMode = InterpolationMode.NearestNeighbor;
                g.DrawImage(rawMask, 0, 0, outW, outH);
            }
            rawMask.Dispose();

            // Save final mask if debug enabled
            if (DebugEnabled && SaveDebugImages)
            {
                string debugDir = DebugOutputPath ?? Path.Combine(AppDomain.CurrentDomain.BaseDirectory, "DebugMasks");
                Directory.CreateDirectory(debugDir);
                string filePath = Path.Combine(debugDir, $"Mask_{debugTag}_slice{sliceIndex}_chan{maskIndex}.png");
                finalMask.Save(filePath, ImageFormat.Png);
            }

            return finalMask;
        }
        catch (Exception ex)
        {
            Log($"[BuildMaskFromDecoder] Error processing mask: {ex.Message}");
            Log($"[BuildMaskFromDecoder] Stack trace: {ex.StackTrace}");

            // Return empty mask as fallback
            Bitmap emptyMask = new Bitmap(outW, outH);
            using (Graphics g = Graphics.FromImage(emptyMask))
            {
                g.Clear(Color.Black);
            }
            return emptyMask;
        }
    }


    // ------------------------------------------------------------------------
    // Private helper: Convert raw logits => binarized mask => upscaled to original size
    // ------------------------------------------------------------------------
    private Bitmap BuildMaskFromDecoder(
        Tensor<float> masksTensor,
        int maskIndex,
        int maskW, int maskH,
        int outW, int outH,
        out bool[,] maskBits)
    {
        float threshold = MaskBinarizationThreshold;
        maskBits = new bool[maskH, maskW];

        // Build a 256x256 raw mask
        Bitmap rawMask = new Bitmap(maskW, maskH, PixelFormat.Format24bppRgb);

        // decode channel c
        for (int yy = 0; yy < maskH; yy++)
        {
            for (int xx = 0; xx < maskW; xx++)
            {
                float logit = masksTensor[0, maskIndex, yy, xx];
                float prob = 1f / (1f + (float)Math.Exp(-logit)); // sigmoid
                bool isFg = (prob >= threshold);

                if (isFg)
                {
                    rawMask.SetPixel(xx, yy, Color.White);
                    maskBits[yy, xx] = true;
                }
                else
                {
                    rawMask.SetPixel(xx, yy, Color.Black);
                    maskBits[yy, xx] = false;
                }
            }
        }

        // upscale to outW,outH with nearest neighbor
        Bitmap finalMask = new Bitmap(outW, outH, PixelFormat.Format24bppRgb);
        using (Graphics g = Graphics.FromImage(finalMask))
        {
            g.InterpolationMode = InterpolationMode.NearestNeighbor;
            g.DrawImage(rawMask, 0, 0, outW, outH);
        }
        rawMask.Dispose();

        return finalMask;
    }

    // ------------------------------------------------------------------------
    // Private helper: Convert a Bitmap => float[] => (C,H,W) with SAM normalization
    // ------------------------------------------------------------------------
    private float[] BitmapToFloatTensor(Bitmap bmp, int targetWidth, int targetHeight)
    {
       

        Bitmap resized = new Bitmap(targetWidth, targetHeight);
        using (Graphics g = Graphics.FromImage(resized))
        {
            g.InterpolationMode = InterpolationMode.HighQualityBicubic;
            g.DrawImage(bmp, 0, 0, targetWidth, targetHeight);
        }

        float[] pixelMean = { 123.675f, 116.28f, 103.53f };
        float[] pixelStd = { 58.395f, 57.12f, 57.375f };
        float[] data = new float[3 * targetWidth * targetHeight];
        int idx = 0;
        for (int y = 0; y < targetHeight; y++)
        {
            for (int x = 0; x < targetWidth; x++)
            {
                Color c = resized.GetPixel(x, y);
                // Normalize each channel (treat grayscale as RGB by repetition)
                data[idx++] = (c.R - pixelMean[0]) / pixelStd[0];
                data[idx++] = (c.G - pixelMean[1]) / pixelStd[1];
                data[idx++] = (c.B - pixelMean[2]) / pixelStd[2];
            }
        }
        resized.Dispose();
        return data;
    }

    // ------------------------------------------------------------------------
    // Private helper: retrieving NamedOnnxValue by name
    // ------------------------------------------------------------------------
    private Tensor<T> GetFirstTensorOrNull<T>(
        IDisposableReadOnlyCollection<DisposableNamedOnnxValue> outputs,
        string name)
    {
        foreach (var o in outputs)
        {
            if (o.Name == name) return o.AsTensor<T>();
        }
        return null; // not found
    }

    // ------------------------------------------------------------------------
    // Debugging utilities
    // ------------------------------------------------------------------------
    private void DumpTensorStats(Tensor<float> tensor, string tag, int sliceIndex)
    {
        // shape [1, channels, H, W]
        if (tensor == null) return;
        int cdim = tensor.Dimensions[1];
        int hdim = tensor.Dimensions[2];
        int wdim = tensor.Dimensions[3];

        Log($"[DumpTensorStats] slice={sliceIndex}, tag={tag}, shape=[1,{cdim},{hdim},{wdim}]");

        for (int c = 0; c < cdim; c++)
        {
            float minv = float.MaxValue;
            float maxv = float.MinValue;
            double sumv = 0;
            long count = 0;

            // Also count how many are >= 0.0 logit => prob>=0.5
            long fgApprox = 0;

            for (int y = 0; y < hdim; y++)
            {
                for (int x = 0; x < wdim; x++)
                {
                    float val = tensor[0, c, y, x];
                    if (val < minv) minv = val;
                    if (val > maxv) maxv = val;
                    sumv += val;
                    count++;

                    if (val >= 0) fgApprox++;  // logit>=0 => prob>=0.5
                }
            }
            float avg = (float)(sumv / count);
            float fgFrac = (float)fgApprox / (float)count;

            Log($"   Channel {c}: min={minv:F3}, max={maxv:F3}, mean={avg:F3}, #>0 = {fgFrac * 100:F1}%");
        }
    }

    private void SaveMaskChannelAsImage(Tensor<float> tensor, int channelIndex,
                                        int sliceIndex, string debugTag, bool rawLogits)
    {
        // shape [1,3,256,256] or [1,3,H,W]
        int cdim = tensor.Dimensions[1];
        int hdim = tensor.Dimensions[2];
        int wdim = tensor.Dimensions[3];
        if (channelIndex < 0 || channelIndex >= cdim) return;

        string debugDir = DebugOutputPath ?? Path.Combine(AppDomain.CurrentDomain.BaseDirectory, "DebugMasks");
        Directory.CreateDirectory(debugDir);

        // We'll build a grayscale image representing the raw logits or the probability
        Bitmap bmp = new Bitmap(wdim, hdim, PixelFormat.Format24bppRgb);

        // find min/max so we can scale to [0..255] for visualization
        float minv = float.MaxValue;
        float maxv = float.MinValue;
        for (int y = 0; y < hdim; y++)
        {
            for (int x = 0; x < wdim; x++)
            {
                float val = tensor[0, channelIndex, y, x];
                if (val < minv) minv = val;
                if (val > maxv) maxv = val;
            }
        }
        // Avoid degenerate case
        if (minv == maxv) maxv = minv + 1e-5f;

        for (int y = 0; y < hdim; y++)
        {
            for (int x = 0; x < wdim; x++)
            {
                float val = tensor[0, channelIndex, y, x];
                float mapped;
                if (rawLogits)
                {
                    // logit => scale from [minv..maxv] to [0..255]
                    mapped = (val - minv) / (maxv - minv);
                }
                else
                {
                    // probability => sigmoid
                    float prob = 1f / (1f + (float)Math.Exp(-val));
                    mapped = prob;
                }
                byte g = (byte)(mapped * 255.0f);
                bmp.SetPixel(x, y, Color.FromArgb(g, g, g));
            }
        }

        string postfix = rawLogits ? "rawLogits" : "prob";
        string filename = $"MaskRaw_{debugTag}_slice{sliceIndex}_chan{channelIndex}_{postfix}.png";
        string path = Path.Combine(debugDir, filename);
        bmp.Save(path, ImageFormat.Png);
        bmp.Dispose();

        Log($"[SaveMaskChannelAsImage] Wrote {postfix} for channel={channelIndex} to {path}");
    }
    #region PropagatorOverloads
    /// <summary>
    /// Processes an XY slice with optional 'prevMaskLogits' as mask_input. 
    /// Returns a binarized bool[,] mask (true = foreground).
    /// </summary>
    public bool[,] ProcessXYSlice_WithMaskInput(
        Bitmap baseXY,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName,
        float[] prevMaskLogits,
        int origW,
        int origH)
    {
        // 1) Check session & inputs
        if (_encoderSession == null || _decoderSession == null)
        {
            Log("[ProcessXYSlice_WithMaskInput] No loaded sessions. Returning null.");
            return null;
        }
        if (baseXY == null)
        {
            Log("[ProcessXYSlice_WithMaskInput] baseXY is null. Returning null.");
            return null;
        }

        // 2) Encode the image
        float[] imageTensor = BitmapToFloatTensor(baseXY, _imageInputSize, _imageInputSize);
        var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });
        Tensor<float> imgEmbed, hr0, hr1;
        using (var encOut = _encoderSession.Run(new[]
        {
        NamedOnnxValue.CreateFromTensor("image", imageInput)
    }))
        {
            imgEmbed = GetFirstTensorOrNull<float>(encOut, "image_embed");
            hr0 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
            hr1 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
        }
        if (imgEmbed == null || hr0 == null || hr1 == null)
        {
            Log("[ProcessXYSlice_WithMaskInput] Encoder outputs missing. Returning null.");
            return null;
        }

        // 3) Build point prompts => (1, numPoints, 2) for coords & (1, numPoints) for labels
        var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

        // 4) Build mask_input from prevMaskLogits or zeros
        DenseTensor<float> maskTensor;
        DenseTensor<float> hasMaskTensor;
        if (prevMaskLogits != null && prevMaskLogits.Length == 1 * 1 * 256 * 256)
        {
            maskTensor = new DenseTensor<float>(prevMaskLogits, new[] { 1, 1, 256, 256 });
            hasMaskTensor = new DenseTensor<float>(new float[] { 1 }, new[] { 1 });
        }
        else
        {
            maskTensor = new DenseTensor<float>(new float[1 * 1 * 256 * 256], new[] { 1, 1, 256, 256 });
            hasMaskTensor = new DenseTensor<float>(new float[] { 0 }, new[] { 1 });
        }

        // 5) Build orig_im_size
        var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });

        // 6) Run decoder => get masks + iou
        Tensor<float> masksTensor, iouTensor;
        using (var decOut = _decoderSession.Run(new List<NamedOnnxValue>
    {
        NamedOnnxValue.CreateFromTensor("image_embed",      imgEmbed),
        NamedOnnxValue.CreateFromTensor("high_res_feats_0", hr0),
        NamedOnnxValue.CreateFromTensor("high_res_feats_1", hr1),
        NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
        NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
        NamedOnnxValue.CreateFromTensor("mask_input",       maskTensor),
        NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskTensor),
        NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
    }))
        {
            masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");
            iouTensor = GetFirstTensorOrNull<float>(decOut, "iou_predictions");
        }
        if (masksTensor == null || iouTensor == null)
        {
            Log("[ProcessXYSlice_WithMaskInput] Decoder output missing. Returning null.");
            return null;
        }

        // 7) Select best channel by IoU
        int outC = masksTensor.Dimensions[1];
        float bestIoU = float.MinValue;
        int bestIndex = 0;
        for (int c = 0; c < outC; c++)
        {
            float iouVal = iouTensor[0, c];
            if (iouVal > bestIoU)
            {
                bestIoU = iouVal;
                bestIndex = c;
            }
        }
        Log($"[ProcessXYSlice_WithMaskInput] Best channel={bestIndex}, IoU={bestIoU:F3}");

        // 8) Convert that channel’s logits => bool[,] mask
        bool[,] binMask = BuildMaskArrayFromLogits(masksTensor, bestIndex, origW, origH);
        return binMask;
    }

    /// <summary>
    /// Processes an XZ slice with optional 'prevMaskLogits' as mask_input. 
    /// Returns a binarized bool[,] mask (true = foreground).
    /// </summary>
    public bool[,] ProcessXZSlice_WithMaskInput(
        Bitmap baseXZ,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName,
        float[] prevMaskLogits,
        int origW,
        int origH)
    {
        if (_encoderSession == null || _decoderSession == null)
        {
            Log("[ProcessXZSlice_WithMaskInput] No loaded sessions. Returning null.");
            return null;
        }
        if (baseXZ == null)
        {
            Log("[ProcessXZSlice_WithMaskInput] baseXZ is null. Returning null.");
            return null;
        }

        // 1) Encode
        float[] imageTensor = BitmapToFloatTensor(baseXZ, _imageInputSize, _imageInputSize);
        var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });
        Tensor<float> imgEmbed, hr0, hr1;
        using (var encOut = _encoderSession.Run(new[]
        {
        NamedOnnxValue.CreateFromTensor("image", imageInput)
    }))
        {
            imgEmbed = GetFirstTensorOrNull<float>(encOut, "image_embed");
            hr0 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
            hr1 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
        }
        if (imgEmbed == null || hr0 == null || hr1 == null)
        {
            Log("[ProcessXZSlice_WithMaskInput] Encoder outputs missing. Returning null.");
            return null;
        }

        // 2) Prompts
        var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

        // 3) Mask input
        DenseTensor<float> maskTensor;
        DenseTensor<float> hasMaskTensor;
        if (prevMaskLogits != null && prevMaskLogits.Length == 1 * 1 * 256 * 256)
        {
            maskTensor = new DenseTensor<float>(prevMaskLogits, new[] { 1, 1, 256, 256 });
            hasMaskTensor = new DenseTensor<float>(new float[] { 1 }, new[] { 1 });
        }
        else
        {
            maskTensor = new DenseTensor<float>(new float[1 * 1 * 256 * 256], new[] { 1, 1, 256, 256 });
            hasMaskTensor = new DenseTensor<float>(new float[] { 0 }, new[] { 1 });
        }

        // 4) orig_im_size => [origH, origW]
        var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });

        // 5) Decode
        Tensor<float> masksTensor, iouTensor;
        using (var decOut = _decoderSession.Run(new List<NamedOnnxValue>
    {
        NamedOnnxValue.CreateFromTensor("image_embed",      imgEmbed),
        NamedOnnxValue.CreateFromTensor("high_res_feats_0", hr0),
        NamedOnnxValue.CreateFromTensor("high_res_feats_1", hr1),
        NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
        NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
        NamedOnnxValue.CreateFromTensor("mask_input",       maskTensor),
        NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskTensor),
        NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
    }))
        {
            masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");
            iouTensor = GetFirstTensorOrNull<float>(decOut, "iou_predictions");
        }
        if (masksTensor == null || iouTensor == null)
        {
            Log("[ProcessXZSlice_WithMaskInput] Decoder output missing. Returning null.");
            return null;
        }

        // 6) Pick best by IoU
        int outC = masksTensor.Dimensions[1];
        float bestIoU = float.MinValue;
        int bestIndex = 0;
        for (int c = 0; c < outC; c++)
        {
            float iouVal = iouTensor[0, c];
            if (iouVal > bestIoU)
            {
                bestIoU = iouVal;
                bestIndex = c;
            }
        }
        Log($"[ProcessXZSlice_WithMaskInput] Best channel={bestIndex}, IoU={bestIoU:F3}");

        // 7) Convert logits => bool[,] 
        bool[,] binMask = BuildMaskArrayFromLogits(masksTensor, bestIndex, origW, origH);
        return binMask;
    }

    /// <summary>
    /// Processes a YZ slice with optional 'prevMaskLogits' as mask_input. 
    /// Returns a binarized bool[,] mask (true = foreground).
    /// </summary>
    public bool[,] ProcessYZSlice_WithMaskInput(
        Bitmap baseYZ,
        List<AnnotationPoint> slicePoints,
        string targetMaterialName,
        float[] prevMaskLogits,
        int origW,
        int origH)
    {
        if (_encoderSession == null || _decoderSession == null)
        {
            Log("[ProcessYZSlice_WithMaskInput] No loaded sessions. Returning null.");
            return null;
        }
        if (baseYZ == null)
        {
            Log("[ProcessYZSlice_WithMaskInput] baseYZ is null. Returning null.");
            return null;
        }

        // 1) Encode
        float[] imageTensor = BitmapToFloatTensor(baseYZ, _imageInputSize, _imageInputSize);
        var imageInput = new DenseTensor<float>(imageTensor, new[] { 1, 3, _imageInputSize, _imageInputSize });
        Tensor<float> imgEmbed, hr0, hr1;
        using (var encOut = _encoderSession.Run(new[]
        {
        NamedOnnxValue.CreateFromTensor("image", imageInput)
    }))
        {
            imgEmbed = GetFirstTensorOrNull<float>(encOut, "image_embed");
            hr0 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_0");
            hr1 = GetFirstTensorOrNull<float>(encOut, "high_res_feats_1");
        }
        if (imgEmbed == null || hr0 == null || hr1 == null)
        {
            Log("[ProcessYZSlice_WithMaskInput] Encoder outputs missing. Returning null.");
            return null;
        }

        // 2) Prompts
        var (coordTensor, labelTensor) = BuildSinglePromptTensors(slicePoints, origW, origH, targetMaterialName);

        // 3) Mask input
        DenseTensor<float> maskTensor;
        DenseTensor<float> hasMaskTensor;
        if (prevMaskLogits != null && prevMaskLogits.Length == 1 * 1 * 256 * 256)
        {
            maskTensor = new DenseTensor<float>(prevMaskLogits, new[] { 1, 1, 256, 256 });
            hasMaskTensor = new DenseTensor<float>(new float[] { 1 }, new[] { 1 });
        }
        else
        {
            maskTensor = new DenseTensor<float>(new float[1 * 1 * 256 * 256], new[] { 1, 1, 256, 256 });
            hasMaskTensor = new DenseTensor<float>(new float[] { 0 }, new[] { 1 });
        }

        // 4) orig_im_size => [origH, origW]
        var origSizeTensor = new DenseTensor<int>(new[] { origH, origW }, new[] { 2 });

        // 5) Decode
        Tensor<float> masksTensor, iouTensor;
        using (var decOut = _decoderSession.Run(new List<NamedOnnxValue>
    {
        NamedOnnxValue.CreateFromTensor("image_embed",      imgEmbed),
        NamedOnnxValue.CreateFromTensor("high_res_feats_0", hr0),
        NamedOnnxValue.CreateFromTensor("high_res_feats_1", hr1),
        NamedOnnxValue.CreateFromTensor("point_coords",     coordTensor),
        NamedOnnxValue.CreateFromTensor("point_labels",     labelTensor),
        NamedOnnxValue.CreateFromTensor("mask_input",       maskTensor),
        NamedOnnxValue.CreateFromTensor("has_mask_input",   hasMaskTensor),
        NamedOnnxValue.CreateFromTensor("orig_im_size",     origSizeTensor)
    }))
        {
            masksTensor = GetFirstTensorOrNull<float>(decOut, "masks");
            iouTensor = GetFirstTensorOrNull<float>(decOut, "iou_predictions");
        }
        if (masksTensor == null || iouTensor == null)
        {
            Log("[ProcessYZSlice_WithMaskInput] Decoder output missing. Returning null.");
            return null;
        }

        // 6) Pick best
        int outC = masksTensor.Dimensions[1];
        float bestIoU = float.MinValue;
        int bestIndex = 0;
        for (int c = 0; c < outC; c++)
        {
            float iouVal = iouTensor[0, c];
            if (iouVal > bestIoU)
            {
                bestIoU = iouVal;
                bestIndex = c;
            }
        }
        Log($"[ProcessYZSlice_WithMaskInput] Best channel={bestIndex}, IoU={bestIoU:F3}");

        // 7) Convert logits => bool[,]
        bool[,] binMask = BuildMaskArrayFromLogits(masksTensor, bestIndex, origW, origH);
        return binMask;
    }

    /// <summary>
    /// Converts a selected channel’s 256x256 logits to a bool[,] at the original size, 
    /// using nearest-neighbor upsampling and the MaskBinarizationThreshold property.
    /// </summary>
    private bool[,] BuildMaskArrayFromLogits(Tensor<float> masksTensor, int channelIndex,
                                             int origW, int origH)
    {
        int maskH = masksTensor.Dimensions[2]; // typically 256
        int maskW = masksTensor.Dimensions[3]; // typically 256

        bool[,] binMask = new bool[origH, origW];
        for (int y = 0; y < origH; y++)
        {
            int yy256 = (int)Math.Round((y / (float)(origH - 1)) * (maskH - 1));

            for (int x = 0; x < origW; x++)
            {
                int xx256 = (int)Math.Round((x / (float)(origW - 1)) * (maskW - 1));
                float logit = masksTensor[0, channelIndex, yy256, xx256];
                logit = -logit;
                float prob = 1f / (1f + (float)Math.Exp(-logit));
                binMask[y, x] = (prob >= MaskBinarizationThreshold);
            }
        }
        return binMask;
    }
    #endregion
}
